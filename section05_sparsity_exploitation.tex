\section{Sparsity Exploitation Technique} \label{sec:exploit_sparsity}
\subsection{Semidefinite cone} \label{sec:exploit_sparsity_sdp}
The dominant computational cost in the algorithms described so far arises from the calculation of $M^p$ when $\mathbb{K}^p = \mathbb{S}^{n_p}_+$. 
Naively calculating this requires repeating matrix multiplications twice and inner product calculations $O(m^2)$ times, making it crucial to leverage the sparsity of $a^p_k$ for practical efficiency. 
Here, we introduce a slightly modified idea proposed by Fujisawa et al.\cite{Fujisawa1997}.

\medskip

In the HKM direction, we have
\[
  M^p_{\sigma(i)\sigma(j)}
  = \inprod{\,a^p_{\sigma(i)}}{\,x^p\,a^p_{\sigma(j)}\,(z^p)^{-1}}
\]
Thus, it is important to note that we only need to calculate the elements corresponding to the non-zero elements of $a^p_{\sigma(i)}$, rather than all elements of $x^p\,a^p_{\sigma(j)}\,(z^p)^{-1}$.
Additionally, since $M^p$ is a symmetric matrix, we only need to calculate the upper triangular elements.

\medskip

Let $f_k$ denote the number of non-zero elements in $a^p_k$, and let $\sigma$ be a permutation of indices $1,\ldots,m$ such that $f_k$ is in ascending order.
For a fixed $j$, define the set
\[
  I
  := \bigl\{(\alpha,\beta)\mid (a^p_{\sigma(i)})_{\alpha\beta}\neq 0
         \text{ for some } i=1,\ldots,j \bigr\}
\]
We consider calculating $x^p\,a^p_{\sigma(j)}\,(z^p)^{-1}$ using one of the methods F1--F3, focusing on the number of multiplications required.

\begin{enumerate}
\item[F1:] First, calculate $F=a_{\sigma(j)}\,(z^p)^{-1}$ (requires $n\,f_{\sigma(j)}$ multiplications).
           Then, calculate $G=x^p\,F$ (requires $n^3$ multiplications).
           Thus, a total of $n\,f_{\sigma(j)} + n^3$ multiplications are required.
\item[F2:] Calculate $F=a_{\sigma(j)}\,(z^p)^{-1}$ (requires $n\,f_{\sigma(j)}$ multiplications). Then,
  \[
    G_{\alpha\beta}=
    \begin{cases}
     \sum_{\gamma=1}^m (x^p)_{\alpha\gamma}\,F_{\gamma\beta}, & \text{if } (\alpha,\beta)\in I,\\
     0, & \text{otherwise},
    \end{cases}
  \]
  (requires $n\,|I|$ multiplications).  
  Thus, a total of $n\,f_{\sigma(j)} + n\,|I|\kappa$ multiplications are required.
\item[F3:] Calculate each element of $G$ directly using the double sum:
  \[
    G_{\alpha\beta}=
    \begin{cases}
      \sum_{\gamma}\sum_{\delta}
        (x^p)_{\alpha\gamma}\,(a^p_{\sigma(j)})_{\gamma\delta}\,(z^p)^{-1}_{\delta\beta},
       & \text{if } (\alpha,\beta) \in I,\\
      0, & \text{otherwise},
    \end{cases}
  \]
  (requires $2f_{\sigma(j)}|I|$ multiplications).
\end{enumerate}

\noindent
F1 is naive and inefficient but has the advantage of utilizing highly optimized Basic Linear Algebra Subroutines (BLAS) for matrix multiplication.
F2 and F3 involve operations on scattered $(\alpha,\beta) \in I$, resulting in higher overhead for memory access, but F2 is advantageous when $|I| \ll n^2$, and F3 is advantageous when $f_{\sigma(j)} \ll n$.

SDPT3 uses...

\medskip

Although the method described here is for the HKM direction, similar techniques can be applied to the NT direction.

\subsection{Second-order and linear cones} \label{sec:exploit_sparsity_socp_lp}
When solving equation \eqref{eq:Schur_complement_Mat} using the methods described in Section~\ref{sec:direction},
if the matrices $\mathcal{M}$ and $M$ are sparse, we can speed up matrix-vector multiplications within the SQMR method and utilize highly optimized Cholesky decomposition and LU decomposition routines such as CHOLMOD, UMFPACK, and SparseLU.

In practical large-scale problems, $M$ is often a low-rank perturbation of a sparse positive definite matrix $M_{\mathrm{sparse}}$. This is because most $a^p_k$ are sparse, and only a few $a^p_k$ are dense.
Here, we introduce a \textbf{sparsity exploitation technique} that can be utilized in such cases.

Assume that for any $p\in P\setminus P^u$, there exist sufficiently small positive integers $n^p_+(\ll m)$ and matrices $M^p_{\mathrm{sparse}} \in \mathbb{S}^m_+$, $U^p \in \mathbb{R}^{m\times n^p_+}$, $D^p\in \mathbb{S}^{n^p_+}$ such that
\begin{equation}
  M^p = M^p_{\mathrm{sparse}} + U^p\, D^p\, (U^p)^T
  \label{eq:low_rank_perturbation}
\end{equation}
Let 
\begin{itemize}
\item $M_{\mathrm{sparse}} := \sum_{p\in P\setminus P^u} M^p_{\mathrm{sparse}}$,
\item $U := [U^p \text{horizontally concatenated}]$, 
\item $D:=[D^p\text{block diagonally concatenated}]$,
\end{itemize}
then the following linear equation
\begin{equation}
  \begin{pmatrix}
    M_{\mathrm{sparse}} & A^u & U \\
    (A^u)^T & O & O \\
    U^T & O & -D^{-1}
  \end{pmatrix}
  \begin{pmatrix}
    \Delta y \\
    \Delta x^u \\
    \lambda
  \end{pmatrix}
  =
  \begin{pmatrix}
    h \\
    R^u_{dual} \\
    0
  \end{pmatrix}
  \label{eq:Schur_complement_Mat_aug}
\end{equation}
has a solution $\lambda = D\,U^T\,\Delta y$, indicating that equations \eqref{eq:Schur_complement_Mat_aug} and \eqref{eq:Schur_complement_Mat} are essentially equivalent.
The coefficient matrix in \eqref{eq:Schur_complement_Mat_aug} is a square matrix of dimension $m+\sum_{p\in P\setminus P^u} n^p$, which is larger than the $m$-dimensional square matrix in \eqref{eq:Schur_complement_Mat}, but has the advantage of being sparse.
This equation \eqref{eq:Schur_complement_Mat_aug} can be solved using the same methods as in Section~\ref{sec:direction}
(specifically, replacing $A^u$ with $[\,A^u, U]$ and $O$ with $\begin{pmatrix} O & O \\ O & -D^{-1} \end{pmatrix}$).

\medskip

Unfortunately, when $\mathbb{K}^p = \mathbb{S}^{n_p}_+$ for some $p \in P$, $M^p$ is often a dense matrix without specific structure, making it difficult to express in the form of \eqref{eq:low_rank_perturbation}.
On the other hand, if $\mathbb{K}^p \neq \mathbb{S}^{n_p}_+$ for any $p\in P$, it may be possible to reduce to \eqref{eq:Schur_complement_Mat_aug}.

\medskip

Below, we describe specific methods for constructing $M^p_{\mathrm{sparse}}$, $U^p$, and $D^p$ when $\mathbb{K}^p \neq \mathbb{S}^{n_p}_+$.
Let $A^p_{\mathrm{sparse}}$ be the matrix obtained by extracting the sparse columns of $A^p$, and $A^p_{\mathrm{dense}}$ be the matrix obtained by extracting the dense columns.
If $A^p_{\mathrm{dense}}$ is empty, let $M^p_{\mathrm{sparse}} = M^p$, and $U^p$, $D^p$ be empty matrices.
Below, we consider the case where $A^p_{\mathrm{dense}}$ is non-empty.

\paragraph{Second-order cone:}

When $\mathbb{K}^p=\mathbb{Q}^{n_p}$, using $-J = I - 2\,e^p(e^p)^T$, we have
\[
  M^p 
  = \bigl((x^p)^T J (z^p)^{-1}\bigr)\, A^p(A^p)^T
    \;+\; u^p (v^p)^T
    \;+\; v^p (u^p)^T
    \;-\; 2\,((x^p)^T J (z^p)^{-1})\, k^p (k^p)^T,
\]
where $u^p := A^p x^p$, $v^p := A^p (z^p)^{-1}$, $k^p := A^p e^p$.
Note that if $A^p_{\mathrm{dense}}$ is non-empty, $u^p, v^p$ are likely to be dense vectors.

Based on this, SDPT3 defines $M^p_{\mathrm{sparse}}$, $U^p$, and $D^p$ as follows:
\[
  M^p_{\mathrm{sparse}}
    := \bigl((x^p)^T J (z^p)^{-1}\bigr)\,
       A^p_{\mathrm{sparse}}\,(A^p_{\mathrm{sparse}})^T,
\]
\[
  U^p
    := \Bigl(\sqrt{(x^p)^T J (z^p)^{-1}}\;A^p_{\mathrm{dense}},
       \;\;\gamma(z^p)^2\,u^p,\;\;\gamma(z^p)^2\,v^p,
       \;-\sqrt{2\,((x^p)^T J (z^p)^{-1})}\,k^p\Bigr),
\]
\[
  D^p
    := \begin{pmatrix}
         I & O & O & O \\
         O & 0 & 1/\gamma(z^p)^2 & 0 \\
         O & 1/\gamma(z^p)^2 & 0 & 0 \\
         O & 0 & 0 & -1
       \end{pmatrix}.
\]
In practice, $M^p = M^p_{\mathrm{sparse}} + U^p D^p (U^p)^T$ holds, and introducing $k^p$ ensures that $M^p_{\mathrm{sparse}}$ is a positive definite matrix.
Note that in implementation, $D^p$ is not directly handled, only $-(D^p)^{-1}$ is needed, which can be written as
\[
  -(D^p)^{-1}
  = \begin{pmatrix}
      -I & O & O & O \\
      O & 0 & -\gamma(z^p)^2 & 0 \\
      O & -\gamma(z^p)^2 & 0 & 0 \\
      O & 0 & 0 & 1
    \end{pmatrix}
\]

\paragraph{Linear cone:}

When $\mathbb{K}^p = \mathbb{R}^{n_p}_+$, it is even simpler.
Let $x^p_{\mathrm{sparse}}, z^p_{\mathrm{sparse}}$ be the vectors obtained by extracting the elements of $x^p, z^p$ corresponding to the sparse columns of $A^p$, and $x^p_{\mathrm{dense}}, z^p_{\mathrm{dense}}$ be the vectors obtained by extracting the elements corresponding to the dense columns.
SDPT3 defines $M^p_{\mathrm{sparse}}$, $U^p$, and $D^p$ as follows:
\[
   M^p_{\mathrm{sparse}}
   = A^p_{\mathrm{sparse}}
     \,\operatorname{diag}(x^p_{\mathrm{sparse}})
     \,\operatorname{diag}(z^p_{\mathrm{sparse}})^{-1}
     \,(A^p_{\mathrm{sparse}})^T,
\]
\[
   U^p
   = \operatorname{diag}(x^p_{\mathrm{sparse}})^{\tfrac12}
     \,\operatorname{diag}(z^p_{\mathrm{sparse}})^{-\tfrac12}
     \,A^p_{\mathrm{dense}},
\]
\[ D^p = I, \]
In practice, $M^p = M^p_{\mathrm{sparse}} + U^p D^p (U^p)^T$ holds, and $M^p_{\mathrm{sparse}}$ is a positive definite matrix.
In this case,
\[-(D^p)^{-1} = -I\]

\medskip